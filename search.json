[
  {
    "objectID": "blog/the-chatbots-are-coming/index.html",
    "href": "blog/the-chatbots-are-coming/index.html",
    "title": "The chatbots are coming",
    "section": "",
    "text": "ü§ñ This week, seven teams of scientists and data scientists collaborated to explore ideas in large language modeling applied to a large new open dataset. Here‚Äôs what happened.\nThe FORCE consortium, which has hosted hackathons and data science contests before (read this and that), hosted another groundbreaking event last week ‚Äî the NPD language modeling hackathon. The event took place at the NPD in Stavanger, Norway, on 29 & 30 November, and 1 December 2023.\nAs in past years, the event was organized by a small team coordinated by Peter Bormann (ConocoPhillips), who not only believes passionately in the importance of open collaboration but is committed to acting on that belief üôå Scroll down for the rest of the organizational credits.\nOne major feature of this event was the large new dataset the team has assembled. This contains almost three million pages of text from various reports published by the Norwegian Petroleum Directorate, Netherlands Oil and Gas and the UK North Sea Transition Authority. It will soon be published under the NLOD 2.0 licence, and should be an exciting resource for the community; we just want to make sure we have taken reasonable steps to protect people‚Äôs privacy before publishing it."
  },
  {
    "objectID": "blog/the-chatbots-are-coming/index.html#projects",
    "href": "blog/the-chatbots-are-coming/index.html#projects",
    "title": "The chatbots are coming",
    "section": "Projects",
    "text": "Projects\nHere‚Äôs a very quick rundown of the teams that formed at what I believe was the first public LLM-based hackathon in Norway or in the energy sector (AkerBP ran one of their own a few weeks ago):\n\nAnonymizers ‚Äî Masking personally identifiable information in public datasets.\nEmbedding enthusiasts ‚Äî Fine-tuning an embeddings model, using cleaner data.\nZero-shot chatbots ‚Äî What kind of questions can chatbots answer about the dataset?\nKnowledge-graphers ‚Äî Extracting a knowledge graph and providing it to chatbots.\nQ&A generators ‚Äî Generating question-answer pairs for fine-tuning Q&A chatbots.\nMetadata extractors ‚Äî Automatically pulling metadata from the dataset.\n\nTomorrow I will put up another post describing the projects in more detail. When it‚Äôs up, you can click here to read it!"
  },
  {
    "objectID": "blog/the-chatbots-are-coming/index.html#credits",
    "href": "blog/the-chatbots-are-coming/index.html#credits",
    "title": "The chatbots are coming",
    "section": "Credits",
    "text": "Credits\nIt takes a community of organizers to pull off a community event like this. Here‚Äôs a probably incomplete list, apologies if I missed anyone (drop me a line!):\n\nJesse Lord, (Kadme and Fabriq) for the dataset, which will soon be released under an open license.\nLukas Mosser, (AkerBP) for the starter notebook and know-how.\nPaul Cleverley, Infoscience for the named entity tags.\nEirik Haughom and Frode Odinsen, Microsoft for the in-event Azure support.\nThe NPD, especially Janke Ro and those involved in FORCE.\nIt was my privilege to facilitate the proceedings, a job I am ill-suited for but enjoy anyway üòÖ Thank you to Peter for the opportunity!"
  },
  {
    "objectID": "blog/force-hackathon-projects.html",
    "href": "blog/force-hackathon-projects.html",
    "title": "FORCE hackathon project round-up",
    "section": "",
    "text": "ü§ñ Yesterday, I summed up last week‚Äôs FORCE large language model hackathon, which took place last week in Stavanger, Norway. Today, let‚Äôs look more closely at the projects our hackers worked on‚Ä¶\n\nAnonymizers\nLynn Vogel (EBN), Odd Kolbj√∏rnsen (AkerBP), Zana Pepaj (Equinor), Petter Dischington (NPD), Jari Kunnas (V√•r Energi).\nThis dataset, and others like it, contains a lot of names ‚Äî¬†of people (Knut Hansen), fields (Johan Sverdrup), equipment (Billy Pugh), and report authors (J. Doe et al). Some uses of some names might be considered personally identifiable information; there are also emails, phone numbers, and other data. The team tried applying a combination of NER models (e.g.¬†with Spacy), specialist anonymization pipelines like Microsoft Presidio, and the Azure OpenAI API to the problem, achieving some success. The team crafted some serious ChatGPT prompts to elicit structured NER labeling, and it was very interesting to see how good the model is at this task.\n‚≠ê The jury understood the task right away, and appreciated the difficulty of completing it. They also liked the relatable way in which the story was told.\n\n\nEmbedding enthusiasts\nRyan Cole (Capgemini), Benjamin Kofoed (Equinor), Kristian de Figueiredo Kollsg√•rd (NPD), George Ghon (Capgemini), Bartek Florczyk Vik.\nEmbeddings of words, sentences, and documents are useful resources in natural language processing. The idea is to cast the corpus into a vector space in which semantically similar entities are close to each other. The team set about creating a clean dataset using various methods from plain regex to transformer-based denoising (TSDAE) in SBERT, then comparing how GPT and SBERT, and a real human geologist, rated the sentences. They were then able to compare sentence similarity using various methods, and score the performance of multiple models, both off-the-shelf and self-trained.\nüåü Special mention Everyone was impressed with this end-to-end data science project, with a pipeline that included data cleaning, and quantitative comparisons between several models.\n\n\nZero-shot chatbots\nJ√∂rg Peisker (OMV), Doris Winkler (OMV), Dennis Schmidt (OMV), Daan Petri (EBN), Dylan Loss (ConocoPhillips).\nThe dream many people have when they first meet a smart chatbot is to be able to ask simple questions with ordinary language, and get back exactly what you wanted. Achieving this dream on a custom dataset is, however, challenging; even mundane things like typos (‚Äòwel‚Äô, ‚Äòwelll‚Äô, ‚Äòweel‚Äô, ‚Äòwlel‚Äô) gave all the teams headaches. This team experimented with various manifestations of the NPD dataset, the LangChain toolkit, cleaning the vector database in various ways, Facebook‚Äôs FAISS project for storing vectors, and extensive prompt engineering ‚Äî¬†which J√∂rg pointed out, ‚Äúis definitely a thing‚Äù.\n‚≠ê The jury appreciated the sharp focus on real business questions, and the subsequent story of what did not work ‚Äî¬†and why. The team put a solid, scientific project together.\n\n\nKnowledge-graphers\nHammad Ali, Catherine Adams, Henrik Busengdal, Anil Dhiman (all Sopra Steria), Thomas Crabie, Adam Hammoumi, Aziz Ben Ammar, Ilyas Tib (all IFPEN), Lars Lukerstuen (Bouvet), Erich Suter (Equinor), and Johannes √Ösheim (Fabriq).\nThe team applied a deep technology stack to exploring the usefulness of graph theory and semantic subject-predicate-object triples in querying large language models. They also explored ways to extract both knowledge graphs and sample questions that would exploit knowledge from multiple documents from datasets like the one we had. With this foundation, the query response pipeline had several elements including:\n\nUse the Azure OpenAI API to convert a user query to a Cypher query (Cypher is Neo4J‚Äôs graph query language).\nApply the query to the Neo4j graph database, and retrieve the result.\nSimultaneously convert the user query to embeddings and fetch the nearest neighbours from the vector database.\nUse ChatGPT to synthesize a response based on the graph and embedding responses, and providing references for its answers.\n\nCheck out the team‚Äôs GitHub repo here.\nüåü Special mention The jury was impressed by the project management skills of this large team, all of whom contributed to the end result. Their graph-based approach has clear value and utility in these problems.\n\n\nQ&A generators\nNolwenn Bernard (UiS), Henri Blondelle (Agile DD), Eirik Morken (Bouvet), Aleksander Jakobsen (Bouvet), Akram Ourir (Sval Energy).\nRecognizing that the long-term goal of a domain-specific chatbot will take a lot of work and collaboration, the team set about creating a large database of question-answer pairs. Apart from being a great hackathon project in itself, such an collection would be a valuable asset to the community, for both training and benchmarking models. Drawing inspriation from Stanford‚Äôs SQuAD dataset, the team used ChatGPT-4 Turbo with a highly customized prompt to generate 11 200 JSON-formatted candidate pairs from a clean subset of the NPD data. Here‚Äôs a simplifed example:\n    {\n        \"Q\": \"What type of sandstone lies in the 15/12-Beta-\n              West reservoir of wellbore 15/12-4?\", \n        \"A\": \"Late Jurassic (Oxfordian) sandstone.\"\n    }\nBased on a sample of 550 questions, the team estimated that about 80% of the pairs were of sufficient quality to meet their needs. In a nod to accessibility and sustainability, the team estimated the compute cost of generating the collection at USD 36 ‚Äî plus about 75 person-hours of labour!\nCheck out the team‚Äôs GitHub repo here.\nüåü Special mention The team did a terrific job of explaining and justifying their goal, and the jury were impressed by this impactful contribution to the community.\n\n\nMetadata extractors\nEnrico Riccardi, Wiktor Weibull, Aksel Hiorth (all UiS), Mads Lorentzen (Geo), Sanjay Kamath, Dorra Nouira (both TotalEnergies).\nAll of the teams faced a noise problem and needed to reduce the training dataset to something models might learn from. This team chose to focus on well entities, focusing on about 10 wells out of more than 4000. The team used the pretrained KeyBERT model to extract keywords/phrases from documents pertaining to a known well, then selected the 18 most relevant and interesting, including things like drilling risk, equipment failure and medical issues. These were combined into custom prompts for ChatGPT-4, which returned structured JSON containing documents from the entire dataset. Once again, the orchestration of an elaborate toolchain being hidden behind deceptively simple outputs ‚Äî perhaps that sums up all of transformer-based NLP!\n‚≠ê The team presented a nice story, grounded in the perspective of a subsurface professional. This teams work promises to be useful to anyone picking up an NLP project in our domain.\n\nThat‚Äôs it for this event! Many thanks to all the participants, who worked so hard to learn new things, put them into action, then share what they learned with everyone else. It was, as always, inspiring to see. I‚Äôm sure there will be more events like this in the future, so stay tuned and look forward to the next one üöÄ\n\n\n\nChangelog\n\n2023-12-04 ‚Äî corrected record of exactly what the knowledge graph team did"
  },
  {
    "objectID": "blog/a-wind-powered-hackathon.html",
    "href": "blog/a-wind-powered-hackathon.html",
    "title": "A wind-powered hackathon",
    "section": "",
    "text": "If you like hackathons, love solving difficult problems, and have a laptop and a good winter coat, then start getting excited!\nüí® I‚Äôm thrilled to announce a new social coding‚Ä† event, happening in Trondheim, Norway, on 15 & 16 January 2024, and this one is all about offshore wind energy.\n\n\nFind out more and sign up\n\n\n‚òùÔ∏è Sign up is free, and there‚Äôs a FAQ on that page to answer your questions. If you have others, drop me a line and I‚Äôll do my best to answer them.\nüß© The theme will be Integration, which you can interpret any way you like. For example, you might look at integrating datasets, or numerical simulations, or turbine components, or power markets, or even project teams.\nüè¢ I‚Äôm stoked about the venue, DIGS, at which I recently had the pleasure of running another (private) hackathon. If the recent news of WeWork‚Äôs bankruptcy got you down about coworking, then DIGS should lift you back up again. It seems to be smashing it for the Trondheim startup community, and has room left over for events.\nüôå Many thanks to John Olav Gi√¶ver Tande, Konstanze K√∂lle and Daniel Albert at SINTEF, for the collaboration on this event. And huge thanks to Equinor for supporting the hackathon financially.\n\n‚Ä† You don‚Äôt have to code, there are lots of ways to take part."
  },
  {
    "objectID": "blog/im-not-stupid-im-just.html",
    "href": "blog/im-not-stupid-im-just.html",
    "title": "I‚Äôm not stupid I‚Äôm just‚Ä¶",
    "section": "",
    "text": "People with a lot of expertise (I don‚Äôt like the word ‚Äòexpert‚Äô) can help others learn and improve by writing. As a bonus, the act of writing reflexively sharpens the expertise. Everyone wins!\nHowever, if you ask someone with great experience and theoretical insight to write a how to wiki page or best practice document, there‚Äôs a good chance it will be 3000 words long, or even shatter into seven 3000-word-long sub-articles. There will probably be equations. Code, if you‚Äôre lucky. References. Valuable documentation of a difficult task, for sure‚Ä¶\n‚Ä¶but completely inappropriate for 90% of use cases. Most people, most of the time, can‚Äôt absorb thousands of words right now. They see the wall of text and immediately smash that back button.\nThe challenge of reducing important ideas to a couple of paragraphs and some bullet points is too much for some. It‚Äôs ‚Äúdumbing down‚Äù, ‚Äúdiluting‚Äù, ‚Äúoversimplifying‚Äù, or pandering to ‚Äúthe lowest common denominator‚Äù. The target audience sometimes participates in this notion with requests to, ‚ÄúExplain it like I‚Äôm 5‚Äù.\nThis is a horrible misunderstanding. Simplistic content for dumb people with childlike vocabularies is not what is being asked for. There are lots of reasons other brilliant people with experience and insight want approachable content sometimes:\n\nThey only have a few minutes right now.\nThey are new to this specific topic.\nThe topic is not a critical issue for them.\nThey are just curious.\nThey just needed a refresher.\nThey are looking for something to link to.\nThey are trying to help someone else.\n\nIt‚Äôs possible that large language models like ChatGPT are especially good at this task of summarization. But I believe it‚Äôs a skill worth honing, if not for writing then for speaking. If you learn to see the loss of precision as a gain in signal strength, perhaps the tradeoff will seem less costly.\nThe result: more smart people will find and read your ideas, and get the help they were looking for."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "FORCE hackathon project round-up\n\n\n\n\n\nAll the projects at the FORCE LLM hackathon in Stavanger\n\n\n\n\n\n\nDec 4, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n  \n\n\n\n\nThe chatbots are coming\n\n\n\n\n\nWhat happened at the FORCE LLM hackathon in Stavanger\n\n\n\n\n\n\nDec 2, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n  \n\n\n\n\nA wind-powered hackathon\n\n\n\n\n\nA new event devoted to offshore wind energy\n\n\n\n\n\n\nNov 27, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n  \n\n\n\n\nI‚Äôm not stupid I‚Äôm just‚Ä¶\n\n\n\n\n\n‚Ä¶curious, ‚Ä¶in a hurry, ‚Ä¶not that interested\n\n\n\n\n\n\nNov 6, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n  \n\n\n\n\nSoftware Underground is moving\n\n\n\n\n\nThe social network for digital geoscientists is moving house\n\n\n\n\n\n\nOct 31, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n  \n\n\n\n\nHackathon season\n\n\n\n\n\nSocial coding is still the best coding\n\n\n\n\n\n\nOct 26, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to scienxlab\n\n\n\n\n\nThe blog is back!\n\n\n\n\n\n\nOct 16, 2023\n\n\nMatt Hall\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "scien‚úñÔ∏èlab is a microscopic scientific laboratory producing open scientific software. Matt Hall / @kwinkunks writes all the bugs, makes all the tea, and adheres to ISO 3103. Find Matt at Software Underground or feel free to get in touch at hello@scienxlab.org"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to scien‚úñÔ∏èlab",
    "section": "",
    "text": "redflag ‚Äî early warning system for machine learning data.\nunmap ‚Äî recovering data from pseudocolor images.\nchecklists ‚Äî simple checklists for high quality data science.\nkata ‚Äî fun coding challenges for geoscientists."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Welcome to scien‚úñÔ∏èlab",
    "section": "",
    "text": "redflag ‚Äî early warning system for machine learning data.\nunmap ‚Äî recovering data from pseudocolor images.\nchecklists ‚Äî simple checklists for high quality data science.\nkata ‚Äî fun coding challenges for geoscientists."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Welcome to scien‚úñÔ∏èlab",
    "section": "Recent posts",
    "text": "Recent posts"
  },
  {
    "objectID": "blog/hackathon-season.html",
    "href": "blog/hackathon-season.html",
    "title": "Hackathon season",
    "section": "",
    "text": "Hackathons aren‚Äôt what they used to be. I think they‚Äôre even better.\nThe golden age of hackathons was 2010 to 20-COVID. Before 2010 I think they were mostly niche Silicon Valley affairs; Agile ran its first hack in 2013 so that‚Äôs when they started for me. I ran 11 of them in 2019‚Ä¶ And it really did end with COVID: I was at an event in Kuala Lumpur when COVID lockdown started.\nHackathons never went away completely, but they definitely dimmed. Happily, they seem to be coming back in style, and while the concept is perhaps not quite as exciting or cool as it was, in some ways the events are better. The frenetic commercial energy of Digital Transformation has faded. The hackers, at least in the subsurface domain, are much more savvy: there‚Äôs data everywhere and everyone knows what an API is. There are far more packages and tools to choose from (with ChatGPT to find them). It‚Äôs become easier to take time out from the office. And while many of the folks who wanted or needed to find their digital feet have achieved their goals, the end of petroleum looms ever larger and I sense that more people see opportunity in it.\nI‚Äôm on my way home from a hackathon right now, my first one for about a year. It was wonderful, just like always. Lots of first-timers, which I love to see, and lots of brilliant ideas. It‚Äôs absolutely the best possible way to spend time with colleagues. If you haven‚Äôt experienced it, you should organize one at your place of work. Here‚Äôs how. Go on, I dare you üöÄ"
  },
  {
    "objectID": "blog/hackathon-season.html#an-invitation",
    "href": "blog/hackathon-season.html#an-invitation",
    "title": "Hackathon season",
    "section": "An invitation",
    "text": "An invitation\nIf you‚Äôre not quite ready to host one, come and experience one instead. The FORCE Language Modeling Hackathon is happening in Stavanger, Norway, on 30 November and 1 December 2023. I‚Äôm stoked to be hosting, with Peter Bormann organizing. The plan is to fine-tune some language models with open subsurface data from the Norwegian shelf. What would you ask a virtual assistant that has read everything about your project?\n\nFind out more and sign up!\n\n\n\nChangelog\n\n2023-12-01 ‚Äî fixed typo"
  },
  {
    "objectID": "blog/software-underground-is-moving.html",
    "href": "blog/software-underground-is-moving.html",
    "title": "Software Underground is moving",
    "section": "",
    "text": "The Software Underground ‚Äî a free chat group, a community, a movement ‚Äî¬†is moving to the Mattermost platform. As of right now, it lives at mattermost.softwareunderground.org.\nAfter a little over 8 years on Slack, we have taken the decision to move to the open-source Mattermost software (note, that link is only for the software, not for our instance of it). We are hosting it ourselves in Hetzner‚Äôs cloud (based in Finland), which means we own our own data‚Ä¶ and maybe have a little more control over our destiny.\nApart from being open source, there are some other cool features of Mattermost, compared to Slack:\n\nFull support for Markdown, plus LaTeX equations.\nSyntax highlighted code blocks.\nThe concept of Teams, allowing us to host subcommunities.\n\nOh yeah, and it will cost us about a third of what we were previously spending on Slack üí∏¬†that is, until they doubled our payments in September when apparently they changed how they count ‚Äòactive members‚Äô. Even with the 85% non-profit discount, Slack was simply too expensive. And some people were not comfortable with its ownership and general direction. For example, it recently introduced a 90-day message lifetime for teams on the free tier, all but obviating its use for smaller communities (who already had a 10,000 message limit).\nIf you‚Äôve been looking for somewhere to hang out and chat ‚Äî¬†or even just to lurk and learn ‚Äî¬†about the digital subsurface, then Software Underground might be for you. It‚Äôs full of coders, people learning to code, earth scientists, and people learning to earth science. Check it out."
  },
  {
    "objectID": "blog/welcome-to-scienxlab.html",
    "href": "blog/welcome-to-scienxlab.html",
    "title": "Welcome to scienxlab",
    "section": "",
    "text": "A lot has happened in the 413 days since my last blog post.\nWith my colleagues, I shut down Agile in September. With my family, I packed up my house in October and moved to Norway in November. With my new colleagues, I found my feet in Equinor in December, and that adventure continues.\nHaving started my career as a geologist, then reconfigured as a geophysicist, I‚Äôm proud to call myself a developer today. I still have tons to learn about maintaining large projects in an enterprise setting, but I do make things and I consider that to be the killer feature of any hacker.\nA few people have asked me what it‚Äôs like to have a boss again, or work inside a big corporation. But really, it‚Äôs not that different from working with corporate clients. I still have a lot of self-determination, thanks to the progressive style of the awesome team I work in, and the only thing I really miss is being able to decide for myself that I‚Äôd like to spend $10k on a hackathon.\nLife outside work is full of hikes and bikes, far-flung fjords and cosy cabins. My Norwegian is a bit rusty (my wife and I lived here in the nineties) but basically functional. We found a house to live in, though it did require some downsizing.\nIn case you hadn‚Äôt noticed, this blog post is more of a postcard to the many friends and co-conspirators I‚Äôve completely failed to keep in touch with. With luck, the coming months and years will provide many opportunities to catch up in person.\nFor now though‚Ä¶ the blog is back! Scien‚úñÔ∏èlab is here üöÄ"
  }
]