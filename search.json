[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "No more AI clichés\n\n\n\n\n\nStop using these tired AI tropes\n\n\n\n\n\nFeb 6, 2024\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nDeepWind hackathon project round-up\n\n\n\n\n\nWhat went down at the DeepWind hackathon in Trondheim\n\n\n\n\n\nJan 17, 2024\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nFORCE hackathon project round-up\n\n\n\n\n\nAll the projects at the FORCE LLM hackathon in Stavanger\n\n\n\n\n\nDec 4, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nThe chatbots are coming\n\n\n\n\n\nWhat happened at the FORCE LLM hackathon in Stavanger\n\n\n\n\n\nDec 2, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nA wind-powered hackathon\n\n\n\n\n\nA new event devoted to offshore wind energy\n\n\n\n\n\nNov 27, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nI’m not stupid I’m just…\n\n\n\n\n\n…curious, …in a hurry, …not that interested\n\n\n\n\n\nNov 6, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Underground is moving\n\n\n\n\n\nThe social network for digital geoscientists is moving house\n\n\n\n\n\nOct 31, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nHackathon season\n\n\n\n\n\nSocial coding is still the best coding\n\n\n\n\n\nOct 26, 2023\n\n\nMatt Hall\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to scienxlab\n\n\n\n\n\nThe blog is back!\n\n\n\n\n\nOct 16, 2023\n\n\nMatt Hall\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to scien✖️lab",
    "section": "",
    "text": "redflag — early warning system for machine learning data.\nunmap — recovering data from pseudocolor images.\nchecklists — simple checklists for high quality data science.\nkata — fun coding challenges for geoscientists."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Welcome to scien✖️lab",
    "section": "",
    "text": "redflag — early warning system for machine learning data.\nunmap — recovering data from pseudocolor images.\nchecklists — simple checklists for high quality data science.\nkata — fun coding challenges for geoscientists."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Welcome to scien✖️lab",
    "section": "Recent posts",
    "text": "Recent posts"
  },
  {
    "objectID": "blog/deepwind-hackathon-projects/index.html",
    "href": "blog/deepwind-hackathon-projects/index.html",
    "title": "DeepWind hackathon project round-up",
    "section": "",
    "text": "The DeepWind Hackathon happened! It was just as awesome as I thought it would be, with the usual mix of diverse expertise and insight from across Europe and the Americas. I hope it’s the first of many wind-related events, stay tuned!\nI’m new to the wind community, so there was not a lot of chance to feel out projects ahead of this event. So after saying Hello and finding coffee, we began with an hour or so of project pitches, followed by half-an-hour of negotiation and clarification. This simple process is usually enough to land on teams and projects, and this time was no exception. Read about the projects, and the hackers behind them, below.\nAs always in these events, it was impressive to see small groups of enthusiastic strangers come together and magic something out of nothing in less than two days, fuelled only by coffee, tea, and the occasional chocolate brownie."
  },
  {
    "objectID": "blog/deepwind-hackathon-projects/index.html#unicorn-hackers-a-digital-twin-project",
    "href": "blog/deepwind-hackathon-projects/index.html#unicorn-hackers-a-digital-twin-project",
    "title": "DeepWind hackathon project round-up",
    "section": "Unicorn hackers — A digital twin project",
    "text": "Unicorn hackers — A digital twin project\nRudy Yuksel (UMaine), Diederik van Binsbergen (NTNU/VUB), Giovanni Aiosa do Amaral (University of São Paulo), Florian Stadtmann (NTNU), Hallgrim Ludvigsen (Enerbits), Olav Kihle (NTNU), Daniel Yang Hansen (NTNU).\nWith the goal of building a farm-scale digital twin, the team attempted to integrate several datasets and models, and succeeded in building a strong foundation on which to continue iterating. Their system starts with stochastically sampling wind speed and direction from historical data. This feeds a wake model for the wind farm, modeled using FAST.Farm https://github.com/OpenFAST/openfast/tree/main. The result in turn informs an original damage-accumulation fatigue model of the main bearings, in order to predict maintenance needs for each turbine. Finally, a marine safety model searches for an optimal maintenance schedule, using historical wave and weather data. The team also looked at strategies for delaying maintenance by changing operating parameters, for example to reduce the chance of failure during winter.\nThe team made impressive progress on an ambitious goal, implementing an original method for modeling the bearings fatigue with rotational and actual load."
  },
  {
    "objectID": "blog/deepwind-hackathon-projects/index.html#energy-game-project---design",
    "href": "blog/deepwind-hackathon-projects/index.html#energy-game-project---design",
    "title": "DeepWind hackathon project round-up",
    "section": "Energy game project - Design",
    "text": "Energy game project - Design\nFabian Anstock (HAW Hamburg), Ajit Pillai (University of Exeter), Maria Emilia (Mila) Teixeira De Oliveira (Equinor), Olga Usachova (NTNU), Ivana Lapsanka (BAM), Daria Cislo (University of Edinburgh).\nThis was one of two projects focused on creating “the best game of all time” — an educational energy strategy game that Morten Fredriksen had proposed as an outreach aid. The team quickly adopted the energy trilemma, which captures the tension between the equity, sustainability and security of energy sources, as their framework for the design of this game.\nAccordingly, most of the work by this team was analog, collecting open data on average price-per-kWh (reflecting equity), average emissions penalty (sustainability), and the relative reliability and responsiveness (security) of various energy sources relevant to the Norwegian grid: coal, oil, gas, nuclear, hydro, solar, and of course offshore and onshore wind. Scaling the axes of the trilemma to the 0–10 range and multiplying them would provide the final score for a player’s strategy.\n\n\n\nGame designers game designing / Photo: Daniel Albert SINTEF"
  },
  {
    "objectID": "blog/deepwind-hackathon-projects/index.html#energy-game-project---mvp",
    "href": "blog/deepwind-hackathon-projects/index.html#energy-game-project---mvp",
    "title": "DeepWind hackathon project round-up",
    "section": "Energy game project - MVP",
    "text": "Energy game project - MVP\nMorten Fredriksen, Lars Petter Hauge, Fredrik Mellemstrand, Robert Dibble (all Equinor), Roman Sukhanov (independent).\nGitHub repo is here.\nThe energy strategy game was more than just clever game design — a second team implemented a prototype game. The player is challenged with meeting the energy demand of Norway for the first week in January 2024. Adding a baseload of nuclear energy is a good start, but nuclear reactors have historically not been very responsive to high-frequency load changes. Wind and solar can provide substantial energy, and at variable but uncontrollable output levels. Gas is cheap and can follow load perfectly, but has a high carbon penalty… and so on.\nThere was no shortage of feature requests and ideas, the future of this idea is only limited by developer time! And, while there are already sustainable energy games on the web and on Steam (here’s one from ENEL), the down-to-earth realism and real-time data possibilities of this game captured people’s imaginations. Maybe someone should fund this one :)\n\n\n\nGame developers game developing / Photo: Daniel Albert SINTEF"
  },
  {
    "objectID": "blog/deepwind-hackathon-projects/index.html#thank-you",
    "href": "blog/deepwind-hackathon-projects/index.html#thank-you",
    "title": "DeepWind hackathon project round-up",
    "section": "Thank you",
    "text": "Thank you\nAs always, some thanks are due:\n\nMany thanks to the EERA DeepWind Conference, and especailly John Olav Tande and Daniel Albert at SINTEF for the collaboration.\nThe DIGS venue is such a great event space, and Ragnhild Førde looked after us beautifully. Coworking spaces are the best ⭐\nA big thank you to my employer, Equinor, and especially to Lars Petter Hauge, Fredrik Mellemstrand, Mats Andersen and Markus Dregi for extra help figuring out the logistics."
  },
  {
    "objectID": "blog/hackathon-season.html",
    "href": "blog/hackathon-season.html",
    "title": "Hackathon season",
    "section": "",
    "text": "Hackathons aren’t what they used to be. I think they’re even better.\nThe golden age of hackathons was 2010 to 20-COVID. Before 2010 I think they were mostly niche Silicon Valley affairs; Agile ran its first hack in 2013 so that’s when they started for me. I ran 11 of them in 2019… And it really did end with COVID: I was at an event in Kuala Lumpur when COVID lockdown started.\nHackathons never went away completely, but they definitely dimmed. Happily, they seem to be coming back in style, and while the concept is perhaps not quite as exciting or cool as it was, in some ways the events are better. The frenetic commercial energy of Digital Transformation has faded. The hackers, at least in the subsurface domain, are much more savvy: there’s data everywhere and everyone knows what an API is. There are far more packages and tools to choose from (with ChatGPT to find them). It’s become easier to take time out from the office. And while many of the folks who wanted or needed to find their digital feet have achieved their goals, the end of petroleum looms ever larger and I sense that more people see opportunity in it.\nI’m on my way home from a hackathon right now, my first one for about a year. It was wonderful, just like always. Lots of first-timers, which I love to see, and lots of brilliant ideas. It’s absolutely the best possible way to spend time with colleagues. If you haven’t experienced it, you should organize one at your place of work. Here’s how. Go on, I dare you 🚀"
  },
  {
    "objectID": "blog/hackathon-season.html#an-invitation",
    "href": "blog/hackathon-season.html#an-invitation",
    "title": "Hackathon season",
    "section": "An invitation",
    "text": "An invitation\nIf you’re not quite ready to host one, come and experience one instead. The FORCE Language Modeling Hackathon is happening in Stavanger, Norway, on 30 November and 1 December 2023. I’m stoked to be hosting, with Peter Bormann organizing. The plan is to fine-tune some language models with open subsurface data from the Norwegian shelf. What would you ask a virtual assistant that has read everything about your project?\n\nFind out more and sign up!\n\n\n\nChangelog\n\n2023-12-01 — fixed typo"
  },
  {
    "objectID": "blog/im-not-stupid-im-just.html",
    "href": "blog/im-not-stupid-im-just.html",
    "title": "I’m not stupid I’m just…",
    "section": "",
    "text": "People with a lot of expertise (I don’t like the word ‘expert’) can help others learn and improve by writing. As a bonus, the act of writing reflexively sharpens the expertise. Everyone wins!\nHowever, if you ask someone with great experience and theoretical insight to write a how to wiki page or best practice document, there’s a good chance it will be 3000 words long, or even shatter into seven 3000-word-long sub-articles. There will probably be equations. Code, if you’re lucky. References. Valuable documentation of a difficult task, for sure…\n…but completely inappropriate for 90% of use cases. Most people, most of the time, can’t absorb thousands of words right now. They see the wall of text and immediately smash that back button.\nThe challenge of reducing important ideas to a couple of paragraphs and some bullet points is too much for some. It’s “dumbing down”, “diluting”, “oversimplifying”, or pandering to “the lowest common denominator”. The target audience sometimes participates in this notion with requests to, “Explain it like I’m 5”.\nThis is a horrible misunderstanding. Simplistic content for dumb people with childlike vocabularies is not what is being asked for. There are lots of reasons other brilliant people with experience and insight want approachable content sometimes:\n\nThey only have a few minutes right now.\nThey are new to this specific topic.\nThe topic is not a critical issue for them.\nThey are just curious.\nThey just needed a refresher.\nThey are looking for something to link to.\nThey are trying to help someone else.\n\nIt’s possible that large language models like ChatGPT are especially good at this task of summarization. But I believe it’s a skill worth honing, if not for writing then for speaking. If you learn to see the loss of precision as a gain in signal strength, perhaps the tradeoff will seem less costly.\nThe result: more smart people will find and read your ideas, and get the help they were looking for."
  },
  {
    "objectID": "blog/the-chatbots-are-coming/index.html",
    "href": "blog/the-chatbots-are-coming/index.html",
    "title": "The chatbots are coming",
    "section": "",
    "text": "🤖 This week, seven teams of scientists and data scientists collaborated to explore ideas in large language modeling applied to a large new open dataset. Here’s what happened.\nThe FORCE consortium, which has hosted hackathons and data science contests before (read this and that), hosted another groundbreaking event last week — the NPD language modeling hackathon. The event took place at the NPD in Stavanger, Norway, on 29 & 30 November, and 1 December 2023.\nAs in past years, the event was organized by a small team coordinated by Peter Bormann (ConocoPhillips), who not only believes passionately in the importance of open collaboration but is committed to acting on that belief 🙌 Scroll down for the rest of the organizational credits.\nOne major feature of this event was the large new dataset the team has assembled. This contains almost three million pages of text from various reports published by the Norwegian Petroleum Directorate, Netherlands Oil and Gas and the UK North Sea Transition Authority. It will soon be published under the NLOD 2.0 licence, and should be an exciting resource for the community; we just want to make sure we have taken reasonable steps to protect people’s privacy before publishing it."
  },
  {
    "objectID": "blog/the-chatbots-are-coming/index.html#projects",
    "href": "blog/the-chatbots-are-coming/index.html#projects",
    "title": "The chatbots are coming",
    "section": "Projects",
    "text": "Projects\nHere’s a very quick rundown of the teams that formed at what I believe was the first public LLM-based hackathon in Norway or in the energy sector (AkerBP ran one of their own a few weeks ago):\n\nAnonymizers — Masking personally identifiable information in public datasets.\nEmbedding enthusiasts — Fine-tuning an embeddings model, using cleaner data.\nZero-shot chatbots — What kind of questions can chatbots answer about the dataset?\nKnowledge-graphers — Extracting a knowledge graph and providing it to chatbots.\nQ&A generators — Generating question-answer pairs for fine-tuning Q&A chatbots.\nMetadata extractors — Automatically pulling metadata from the dataset.\n\nTomorrow I will put up another post describing the projects in more detail. When it’s up, you can click here to read it!"
  },
  {
    "objectID": "blog/the-chatbots-are-coming/index.html#credits",
    "href": "blog/the-chatbots-are-coming/index.html#credits",
    "title": "The chatbots are coming",
    "section": "Credits",
    "text": "Credits\nIt takes a community of organizers to pull off a community event like this. Here’s a probably incomplete list, apologies if I missed anyone (drop me a line!):\n\nJesse Lord, (Kadme and Fabriq) for the dataset, which will soon be released under an open license.\nLukas Mosser, (AkerBP) for the starter notebook and know-how.\nPaul Cleverley, Infoscience for the named entity tags.\nEirik Haughom and Frode Odinsen, Microsoft for the in-event Azure support.\nThe NPD, especially Janke Ro and those involved in FORCE.\nIt was my privilege to facilitate the proceedings, a job I am ill-suited for but enjoy anyway 😅 Thank you to Peter for the opportunity!"
  },
  {
    "objectID": "blog/a-wind-powered-hackathon.html",
    "href": "blog/a-wind-powered-hackathon.html",
    "title": "A wind-powered hackathon",
    "section": "",
    "text": "If you like hackathons, love solving difficult problems, and have a laptop and a good winter coat, then start getting excited!\n💨 I’m thrilled to announce a new social coding† event, happening in Trondheim, Norway, on 15 & 16 January 2024, and this one is all about offshore wind energy.\n\n\nFind out more and sign up\n\n\n☝️ Sign up is free, and there’s a FAQ on that page to answer your questions. If you have others, drop me a line and I’ll do my best to answer them.\n🧩 The theme will be Integration, which you can interpret any way you like. For example, you might look at integrating datasets, or numerical simulations, or turbine components, or power markets, or even project teams.\n🏢 I’m stoked about the venue, DIGS, at which I recently had the pleasure of running another (private) hackathon. If the recent news of WeWork’s bankruptcy got you down about coworking, then DIGS should lift you back up again. It seems to be smashing it for the Trondheim startup community, and has room left over for events.\n🙌 Many thanks to John Olav Giæver Tande, Konstanze Kölle and Daniel Albert at SINTEF, for the collaboration on this event. And huge thanks to Equinor for supporting the hackathon financially.\n\n† You don’t have to code, there are lots of ways to take part."
  },
  {
    "objectID": "blog/software-underground-is-moving.html",
    "href": "blog/software-underground-is-moving.html",
    "title": "Software Underground is moving",
    "section": "",
    "text": "The Software Underground — a free chat group, a community, a movement — is moving to the Mattermost platform. As of right now, it lives at mattermost.softwareunderground.org.\nAfter a little over 8 years on Slack, we have taken the decision to move to the open-source Mattermost software (note, that link is only for the software, not for our instance of it). We are hosting it ourselves in Hetzner’s cloud (based in Finland), which means we own our own data… and maybe have a little more control over our destiny.\nApart from being open source, there are some other cool features of Mattermost, compared to Slack:\n\nFull support for Markdown, plus LaTeX equations.\nSyntax highlighted code blocks.\nThe concept of Teams, allowing us to host subcommunities.\n\nOh yeah, and it will cost us about a third of what we were previously spending on Slack 💸 that is, until they doubled our payments in September when apparently they changed how they count ‘active members’. Even with the 85% non-profit discount, Slack was simply too expensive. And some people were not comfortable with its ownership and general direction. For example, it recently introduced a 90-day message lifetime for teams on the free tier, all but obviating its use for smaller communities (who already had a 10,000 message limit).\nIf you’ve been looking for somewhere to hang out and chat — or even just to lurk and learn — about the digital subsurface, then Software Underground might be for you. It’s full of coders, people learning to code, earth scientists, and people learning to earth science. Check it out."
  },
  {
    "objectID": "blog/welcome-to-scienxlab.html",
    "href": "blog/welcome-to-scienxlab.html",
    "title": "Welcome to scienxlab",
    "section": "",
    "text": "A lot has happened in the 413 days since my last blog post.\nWith my colleagues, I shut down Agile in September. With my family, I packed up my house in October and moved to Norway in November. With my new colleagues, I found my feet in Equinor in December, and that adventure continues.\nHaving started my career as a geologist, then reconfigured as a geophysicist, I’m proud to call myself a developer today. I still have tons to learn about maintaining large projects in an enterprise setting, but I do make things and I consider that to be the killer feature of any hacker.\nA few people have asked me what it’s like to have a boss again, or work inside a big corporation. But really, it’s not that different from working with corporate clients. I still have a lot of self-determination, thanks to the progressive style of the awesome team I work in, and the only thing I really miss is being able to decide for myself that I’d like to spend $10k on a hackathon.\nLife outside work is full of hikes and bikes, far-flung fjords and cosy cabins. My Norwegian is a bit rusty (my wife and I lived here in the nineties) but basically functional. We found a house to live in, though it did require some downsizing.\nIn case you hadn’t noticed, this blog post is more of a postcard to the many friends and co-conspirators I’ve completely failed to keep in touch with. With luck, the coming months and years will provide many opportunities to catch up in person.\nFor now though… the blog is back! Scien✖️lab is here 🚀"
  },
  {
    "objectID": "blog/no-more-ai-cliches/index.html",
    "href": "blog/no-more-ai-cliches/index.html",
    "title": "No more AI clichés",
    "section": "",
    "text": "The recent resurgence of the word ‘AI’ (it seems like more than a mere abbreviation) brings new communication challenges. The term is so overloaded with so many conflicting meanings as to be useless on its own, without careful delineation. But even a blunt instrument can be useful — and sometimes an advantage. Just remember to sharpen it when you need to.\nThe communication challenges are made worse — much, much worse — by the ham-fisted, unimaginative, and sometimes downright unethical choice of accompanying images. Images which are often generated by AI, cuz we so clever. The generative model was trained on… well, we really have no idea so let’s just say it was effectively trained on everything, ever. Including all previous attempts to illustrate the concept of AI, most of which were probably found in stock (i.e. lame and/or nonsense) images or corporate (also lame) marketing material (lies). Cool.\nSo let’s see what we made. Google Image Search on “AI”, behold:"
  },
  {
    "objectID": "blog/no-more-ai-cliches/index.html#what-does-ai-look-like",
    "href": "blog/no-more-ai-cliches/index.html#what-does-ai-look-like",
    "title": "No more AI clichés",
    "section": "What does AI look like?",
    "text": "What does AI look like?\n\nBlueness (40 out of 72 images, 56%), did IBM start this?\nBrains (14/72, 19%), often split or somehow computerized.\nHumanoids (30/72, 42%), of a very particular type (see below).\nRiffs on The Creation of Adam by Michelangelo (4/72, 5.6%), one of them with the human on the left\nA lot of whatever that holographic display Tom Cruise had in Minority Report\n\nTo be fair, one of the images has some information on it. And some contain actual things that are genuinely relevant, probably by accident:\n\nHumans (14/72, 19%), imagine!\nCircuit boards (8/72, 11%)\nCode (2/72, 2.6%)\nA neural network (1/72, 1.3%)\nComputers (1/72, 1.3%)\n\nIt looks pretty bad from afar — look closer, and it gets worse. The creepy robots are nearly always white, with Western European features and completely devoid of personality or facial expressions. Not only do they appear to have genders, but they are overtly sexualized: the “men” are muscular with chiseled jaws, and the women are conventionally beautiful, often with a human face. And I haven’t counted but I’m willing to bet that most of those in assistant roles are “female”.\nNone of the images contains:\n\nPeople being educated, or showing concern, about AI\nA wind farm or solar array being designed with AI\nA doctor or farmer being assisted by AI\nPeople designing, making or testing AI systems\nPeople regulating or preventing the use of AI\nPhotons with wavelengths longer than 500 nm"
  },
  {
    "objectID": "blog/no-more-ai-cliches/index.html#its-not-just-me",
    "href": "blog/no-more-ai-cliches/index.html#its-not-just-me",
    "title": "No more AI clichés",
    "section": "It’s not just me",
    "text": "It’s not just me\nThings have been written about this. AI Myths has a wonderful article about shiny humanoid robots. A report from boffins at the Royal Society, Portrayals & Perceptions of AI and Why They Matter (2017) is predictably erudite, but predates the current hype cycle. Philipp Schmitt (2021) writes beautifully about the subject. He says,\n\n[These images] are harmful to the public imagination, because metaphors matter. They influence how we develop, think of and design policy for emerging technologies, just as they have for nuclear power or stem cell research in the past.\n\nRomele (2022) goes further, albeit in rather technical language, explicitly condemning several of these tropes as unethical:\n\nWhile the ethics of science communication generally promotes the practice of virtues like modesty, humility, sincerity, transparency, openness, honesty, and generosity, stock images and other popular visual representations of AI are arrogant, pompous, and overconfident. […] The problem with these images is not their lack of reference. Rather, it lies in the way they anesthetize any debate and disagreement about AI.\n\nI agree completely. These images are arrogant. They are becoming part of the popular understanding of AI. They mostly remove actual humans doing actual things with actual AI, and in doing so they collectively tell a huge fib about what AI is, who it is for, and what the issues around it are."
  },
  {
    "objectID": "blog/no-more-ai-cliches/index.html#what-to-do-about-it",
    "href": "blog/no-more-ai-cliches/index.html#what-to-do-about-it",
    "title": "No more AI clichés",
    "section": "What to do about it",
    "text": "What to do about it\nI think we need to stop using these sorts of images immediately. I know they seem ‘right’ — ubiquity is intoxicating. Here, I made you a list of things to look out for, I hope it’s useful:\n\n\n\nList of tropes to avoid in AI illustrations\n\n\nThe good news is, help it at hand! In researching this post, I came across betterimagesofai.org and it’s the best thing ever. Instead of just whining about it like some people, they are “researching, creating, curating and providing Better Images of AI”, and sharing them with the world under open licenses. I love it. And there are some great images in their collection, so check them out.\n Alexa Steinbrück / Better Images of AI / Explainable AI / CC-BY 4.0\n\nReferences\n\nThe Royal Society (2017). Portrayals & Perceptions of AI and Why They Matter, white paper, available online.\nSchmitt, P (2021). Blueprints of Intelligence. Noema Magazine (Berggruen), available online\nRomele, A (2022). Images of Artificial Intelligence: a Blind Spot in AI Ethics. Philosophy & Technology 35 (4). DOI: https://doi.org/10.1007/s13347-022-00498-3\n\n\n\n\nChangelog\n\n2024-02-07 — changed ‘Caucasian’ to ‘Western European’"
  },
  {
    "objectID": "blog/force-hackathon-projects.html",
    "href": "blog/force-hackathon-projects.html",
    "title": "FORCE hackathon project round-up",
    "section": "",
    "text": "🤖 Yesterday, I summed up last week’s FORCE large language model hackathon, which took place last week in Stavanger, Norway. Today, let’s look more closely at the projects our hackers worked on…\n\nAnonymizers\nLynn Vogel (EBN), Odd Kolbjørnsen (AkerBP), Zana Pepaj (Equinor), Petter Dischington (NPD), Jari Kunnas (Vår Energi).\nThis dataset, and others like it, contains a lot of names — of people (Knut Hansen), fields (Johan Sverdrup), equipment (Billy Pugh), and report authors (J. Doe et al). Some uses of some names might be considered personally identifiable information; there are also emails, phone numbers, and other data. The team tried applying a combination of NER models (e.g. with Spacy), specialist anonymization pipelines like Microsoft Presidio, and the Azure OpenAI API to the problem, achieving some success. The team crafted some serious ChatGPT prompts to elicit structured NER labeling, and it was very interesting to see how good the model is at this task.\n⭐ The jury understood the task right away, and appreciated the difficulty of completing it. They also liked the relatable way in which the story was told.\n\n\nEmbedding enthusiasts\nRyan Cole (Capgemini), Benjamin Kofoed (Equinor), Kristian de Figueiredo Kollsgård (NPD), George Ghon (Capgemini), Bartek Florczyk Vik.\nEmbeddings of words, sentences, and documents are useful resources in natural language processing. The idea is to cast the corpus into a vector space in which semantically similar entities are close to each other. The team set about creating a clean dataset using various methods from plain regex to transformer-based denoising (TSDAE) in SBERT, then comparing how GPT and SBERT, and a real human geologist, rated the sentences. They were then able to compare sentence similarity using various methods, and score the performance of multiple models, both off-the-shelf and self-trained.\n🌟 Special mention Everyone was impressed with this end-to-end data science project, with a pipeline that included data cleaning, and quantitative comparisons between several models.\n\n\nZero-shot chatbots\nJörg Peisker (OMV), Doris Winkler (OMV), Dennis Schmidt (OMV), Daan Petri (EBN), Dylan Loss (ConocoPhillips).\nThe dream many people have when they first meet a smart chatbot is to be able to ask simple questions with ordinary language, and get back exactly what you wanted. Achieving this dream on a custom dataset is, however, challenging; even mundane things like typos (‘wel’, ‘welll’, ‘weel’, ‘wlel’) gave all the teams headaches. This team experimented with various manifestations of the NPD dataset, the LangChain toolkit, cleaning the vector database in various ways, Facebook’s FAISS project for storing vectors, and extensive prompt engineering — which Jörg pointed out, “is definitely a thing”.\n⭐ The jury appreciated the sharp focus on real business questions, and the subsequent story of what did not work — and why. The team put a solid, scientific project together.\n\n\nKnowledge-graphers\nHammad Ali, Catherine Adams, Henrik Busengdal, Anil Dhiman (all Sopra Steria), Thomas Crabie, Adam Hammoumi, Aziz Ben Ammar, Ilyas Tib (all IFPEN), Lars Lukerstuen (Bouvet), Erich Suter (Equinor), and Johannes Åsheim (Fabriq).\nThe team applied a deep technology stack to exploring the usefulness of graph theory and semantic subject-predicate-object triples in querying large language models. They also explored ways to extract both knowledge graphs and sample questions that would exploit knowledge from multiple documents from datasets like the one we had. With this foundation, the query response pipeline had several elements including:\n\nUse the Azure OpenAI API to convert a user query to a Cypher query (Cypher is Neo4J’s graph query language).\nApply the query to the Neo4j graph database, and retrieve the result.\nSimultaneously convert the user query to embeddings and fetch the nearest neighbours from the vector database.\nUse ChatGPT to synthesize a response based on the graph and embedding responses, and providing references for its answers.\n\nCheck out the team’s GitHub repo here.\n🌟 Special mention The jury was impressed by the project management skills of this large team, all of whom contributed to the end result. Their graph-based approach has clear value and utility in these problems.\n\n\nQ&A generators\nNolwenn Bernard (UiS), Henri Blondelle (Agile DD), Eirik Morken (Bouvet), Aleksander Jakobsen (Bouvet), Akram Ourir (Sval Energy).\nRecognizing that the long-term goal of a domain-specific chatbot will take a lot of work and collaboration, the team set about creating a large database of question-answer pairs. Apart from being a great hackathon project in itself, such an collection would be a valuable asset to the community, for both training and benchmarking models. Drawing inspriation from Stanford’s SQuAD dataset, the team used ChatGPT-4 Turbo with a highly customized prompt to generate 11 200 JSON-formatted candidate pairs from a clean subset of the NPD data. Here’s a simplifed example:\n    {\n        \"Q\": \"What type of sandstone lies in the 15/12-Beta-\n              West reservoir of wellbore 15/12-4?\", \n        \"A\": \"Late Jurassic (Oxfordian) sandstone.\"\n    }\nBased on a sample of 550 questions, the team estimated that about 80% of the pairs were of sufficient quality to meet their needs. In a nod to accessibility and sustainability, the team estimated the compute cost of generating the collection at USD 36 — plus about 75 person-hours of labour!\nCheck out the team’s GitHub repo here.\n🌟 Special mention The team did a terrific job of explaining and justifying their goal, and the jury were impressed by this impactful contribution to the community.\n\n\nMetadata extractors\nEnrico Riccardi, Wiktor Weibull, Aksel Hiorth (all UiS), Mads Lorentzen (Geo), Sanjay Kamath, Dorra Nouira (both TotalEnergies).\nAll of the teams faced a noise problem and needed to reduce the training dataset to something models might learn from. This team chose to focus on well entities, focusing on about 10 wells out of more than 4000. The team used the pretrained KeyBERT model to extract keywords/phrases from documents pertaining to a known well, then selected the 18 most relevant and interesting, including things like drilling risk, equipment failure and medical issues. These were combined into custom prompts for ChatGPT-4, which returned structured JSON containing documents from the entire dataset. Once again, the orchestration of an elaborate toolchain being hidden behind deceptively simple outputs — perhaps that sums up all of transformer-based NLP!\n⭐ The team presented a nice story, grounded in the perspective of a subsurface professional. This teams work promises to be useful to anyone picking up an NLP project in our domain.\n\nThat’s it for this event! Many thanks to all the participants, who worked so hard to learn new things, put them into action, then share what they learned with everyone else. It was, as always, inspiring to see. I’m sure there will be more events like this in the future, so stay tuned and look forward to the next one 🚀\n\n\n\nChangelog\n\n2023-12-04 — corrected record of exactly what the knowledge graph team did"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "scien✖️lab is a microscopic scientific laboratory producing open scientific software. Matt Hall / @kwinkunks writes all the bugs, makes all the tea, and adheres to ISO 3103. Find Matt at Software Underground or feel free to get in touch at hello@scienxlab.org"
  }
]